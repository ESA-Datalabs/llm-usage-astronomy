{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "911f152e-a8da-41dd-a1d9-72122298e11b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import packages and sleect token\n",
    "import requests\n",
    "import json\n",
    "from urllib.parse import urlencode, quote_plus\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "#import scipy\n",
    "token = 'ATbtiR1atXaREK6hZNc65WhZhvcKphDmRjk0GRG0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18ad736d-b976-48f2-bd34-b0458654a145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get astro document for all years\n",
    "documents_per_year = {}\n",
    "for year in range(2000,2025):\n",
    "    encoded_query = urlencode({\"q\": f'year:{year}',\n",
    "                               \"fq\": \"database:astronomy doctype:article or doctype:eprint or doctype:inproceedings or doctype:inbook\",\n",
    "                               \"fl\": \"year\"})\n",
    "    results = requests.get(\"https://api.adsabs.harvard.edu/v1/search/query?{}\".format(encoded_query), \\\n",
    "                           headers={'Authorization': 'Bearer ' + token})\n",
    "    documents_per_year[str(year)] = results.json()['response']['numFound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36025e5a-de06-45ab-9811-b19282a008f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#define a function to count file per years\n",
    "def year_counter(result_file, beginning=2000, end=2024):\n",
    "    list_of_years = []\n",
    "    for year in result_file:\n",
    "        list_of_years.append(year['year'])\n",
    "    years_count = Counter(list_of_years)\n",
    "    for year in range(beginning,end+1):\n",
    "        if str(year) in years_count:\n",
    "            pass\n",
    "        else:\n",
    "            years_count[str(year)] = 0\n",
    "    return years_count\n",
    "\n",
    "#define function to get those years from search query\n",
    "def astro_search(word, beginning=2000, end=2024, year=False):\n",
    "    if year==False:\n",
    "        year_string = f\"{beginning}-{end}\"\n",
    "    else:\n",
    "        year_string = year\n",
    "    encoded_query = urlencode({\"q\": f\"full:{word}\",\n",
    "                               \"fq\": f\"database:astronomy doctype:article or doctype:eprint or doctype:inproceedings or doctype:inbook entdate:[2000-01-01 TO 2024-05-24] property:refereed year:{year_string}\",\n",
    "                               \"rows\": 2000,\n",
    "                               \"fl\": \"year\"})\n",
    "    results = requests.get(\"https://api.adsabs.harvard.edu/v1/search/query?{}\".format(encoded_query), \\\n",
    "                           headers={'Authorization': 'Bearer ' + token})\n",
    "    number_of_results = results.json()['response']['numFound']\n",
    "    if number_of_results > 50000 and year==False:\n",
    "        astro_count = Counter()\n",
    "        for year in range(beginning,end+1):\n",
    "            year_count = astro_search(word,year=str(year))\n",
    "            astro_count |= year_count\n",
    "    elif 50001 > number_of_results > 2000 and year==False:\n",
    "        start = 0\n",
    "        astro_count = Counter()\n",
    "        while number_of_results > start:\n",
    "            encoded_query = urlencode({\"q\": f'full:{word}',\n",
    "                                       \"fq\": f\"database:astronomy doctype:article or doctype:eprint or doctype:inproceedings or doctype:inbook entdate:[2000-01-01 TO 2024-05-24] property:refereed year:{beginning}-{end}\",\n",
    "                                       \"rows\": 2000,\n",
    "                                       \"fl\": \"year\",\n",
    "                                       \"start\": f\"{start}\"})\n",
    "            results = requests.get(\"https://api.adsabs.harvard.edu/v1/search/query?{}\".format(encoded_query), \\\n",
    "                           headers={'Authorization': 'Bearer ' + token})\n",
    "            astro_count += year_counter(results.json()['response']['docs'])\n",
    "            start += 2000\n",
    "    elif year!=False:\n",
    "        astro_count = {str(year): number_of_results}\n",
    "    else:\n",
    "        astro_count = year_counter(results.json()['response']['docs'])\n",
    "    return astro_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "58dd8a82-33ef-4e78-b505-fc80839dd34a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ai_best_of_best = ['delve', 'underscores', 'delving', 'delves', 'underscored', 'underscoring', 'intricacies', 'groundbreaking', 'scrutinizing', 'meticulous', 'realm', 'meticulously', 'showcases', 'prowess', 'signifies', 'tapestry', 'intricately', 'bolster', 'intricate', 'showcasing', 'dissecting', 'mysteries', 'bolstering', 'unraveling', 'underscore', 'nuanced', 'revolutionize', 'transcends', 'elegance', 'glean', 'revolves', 'nuances', 'amalgamating', 'endeavors', 'underlining', 'embark', 'revolutionizing', 'scrutinized', 'deepen', 'renowned', 'illuminating', 'culminating', 'unearthed', 'solidifies', 'posits', 'culmination', 'pivotal', 'tangible', 'unveils', 'unravels', 'endeavor', 'commendable', 'profound', 'embarked', 'upholding', 'shines', 'fostering', 'adeptly', 'showcased', 'shedding', 'inquiries', 'fascinating', 'feat', 'unravel', 'interconnectedness', 'heightened', 'uphold', 'heralding', 'swiftly', 'elucidating', 'groundwork', 'gleaned', 'bolsters', 'streamlines', 'comprehending', 'elucidation', 'hinting', 'juxtaposing', 'advancing', 'illuminates', 'quest', 'hinted', 'avenues', 'falter', 'underpinnings', 'streamlining', 'safeguarding', 'ventures', 'offering', 'strives', 'intriguing', 'methodical', 'interrelations', 'amidst', 'mathematicians', 'innovative', 'essence', 'crux', 'advancement', 'grappling', 'paving']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d7ed19f0-a492-4814-b136-554b371e431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_favs = ['the', 'this', 'of', 'these', 'within', 'in', 'into', 'by', 'understanding', 'its', 'researchers', 'through', 'approach', 'intricate', 'crucial', 'realm', 'insights', 'significant', 'research', 'their', 'various', 'study', 'analysis', 'systems', 'behavior', 'between', 'potential', 'light', 'framework', 'process', 'scenarios', 'comprehensive', 'leveraging', 'enhancing', 'enhance', 'offering', 'key', 'innovative', 'complex', 'efficiency', 'particularly', 'valuable', 'role', 'but', 's', 'challenges', 'techniques', 'exploration', 'novel', 'involves', 'effectively', 'efficacy', 'lies', 'properties', 'only', 'dynamics', 'context', 'practical', 'specific', 'diverse', 'mathematical', 'interplay', 'deeper', 'address', 'aspect', 'performance', 'traditional', 'moreover', 'effectiveness', 'been', 'one', 'applications', 'structures', 'to', 'has', 'aims', 'overall', 'accuracy', 'across', 'play', 'ability', 'showcasing', 'more', 'theoretical', 'fundamental', 'capabilities', 'underlying', 'intriguing', 'was', 'underscores', 'pivotal', 'not', 'offers', 'ensuring', 'field', 'system', 'unique', 'implications', 'promising', 'investigation', 'conducted', 'characteristics', 'shedding', 'exploring', 'utilizing', 'findings', 'delve', 'challenge', 'essential', 'notable', 'delves', 'world', 'advancements', 'further', 'furthermore', 'way', 'reliability', 'utilization', 'enabling', 'processes', 'methodology', 'nature', 'critical', 'providing', 'robustness', 'tailored', 'making', 'concept', 'nuanced', 'intricacies', 'incorporating', 'impact', 'serves', 'delving', 'advancement', 'relationships', 'outcomes', 'distinct', 'notably', 'tool', 'mechanisms', 'strategies', 'computational', 'towards', 'plays', 'accurately', 'thereby', 'emerges', 'development', 'primary', 'robust', 'like', 'integration', 'addressing', 'landscape', 'demonstrated', 'methodologies', 'conditions', 'enhances', 'focus', 'advanced', 'offer', 'sheds', 'inherent', 'significance', 'patterns', 'complexities', 'phenomena', 'analyzing', 'stands', 'emerged', 'employed', 'broader', 'sophisticated', 'quantum', 'aim', 'often', 'enhanced', 'represents', 'applicability', 'specifically', 'algebraic', 'employing', 'paving', 'essence', 'highlighting', 'fields', 'limitations', 'beyond', 'real', 'avenues', 'remarkable', 'profound', 'interactions', 'focusing', 'showcases', 'such', 'exhibit', 'tasks', 'accurate', 'highlights', 'theory', 'environments', 'optimizing', 'ultimately', 'capturing', 'versatility', 'geometric', 'central', 'opens', 'principles', 'foundation', 'precise', 'detailed', 'introduced', 'serve', 'physics', 'core', 'integrating', 'advancing', 'powerful', 'shed', 'designed', 'introduces', 'leverages', 'fascinating', 'meticulous', 'solutions', 'characterized', 'showcase', 'introduction', 'relationship', 'underscoring', 'efficient', 'superior', 'application', 'need', 'modeling', 'communication', 'optimization', 'meticulously', 'issue', 'processing', 'promise', 'precision', 'validate', 'factors', 'contributes', 'demonstrating', 'significantly', 'involved', 'settings', 'rigorous', 'innovation', 'becomes', 'leading', 'aimed', 'tackle', 'nuances', 'conclusion', 'complexity', 'governing', 'exhibited', 'adaptability', 'handling', 'technique', 'upon', 'establishing', 'spaces', 'examination', 'behaviors', 'groundbreaking', 'technology', 'unravel', 'underscore', 'unraveling', 'efficiently', 'achieving', 'varying', 'reliable', 'substantial', 'connections', 'associated', 'perspective', 'gain', 'importance', 'stability', 'avenue', 'influence', 'revealed', 'while', 'ensure', 'denoted', 'were', 'utility', 'where', 'presence', 'showcased', 'ensures', 'facilitating', 'concerning', 'aspects', 'endeavor', 'comparative', 'gap', 'conventional', 'cutting', 'existing', 'capture', 'analyses', 'phenomenon', 'emphasizing', 'improving', 'strengths', 'revolutionize', 'levels', 'studying', 'boundaries', 'utilized', 'dynamic', 'examining', 'possibilities', 'decision', 'tools', 'validation', 'paves', 'allowing', 'navigate', 'facilitate', 'rich', 'harnessing', 'geometry', 'evaluations', 'identifying', 'advantages', 'extends', 'holds', 'evaluation', 'despite', 'have', 'delved', 'maintaining', 'concepts', 'vital', 'pave', 'investigating', 'additionally', 'domain', 'practitioners', 'involving', 'paramount', 'optimize', 'highlighted', 'dealing', 'technologies', 'established', 'noteworthy', 'poses', 'compelling', 'determining', 'shaping', 'enables', 'elucidating', 'materials', 'regarding', 'investigations', 'foundational', 'especially', 'solution', 'variations', 'posed', 'implementation', 'evolving', 'domains', 'during', 'contexts', 'frameworks', 'strategic', 'balance', 'uncover', 'introducing', 'quest', 'components', 'seamless', 'aiming', 'evaluating', 'comprehension', 'mathematics', 'contributing', 'contribute', 'streamline', 'metrics', 'demonstrates', 'constraints', 'refining', 'impressive', 'limitation', 'endeavors', 'vast', 'elements', 'tapestry', 'individuals', 'incorporation', 'underscored', 'healthcare', 'connection', 'gained', 'seamlessly', 'capability', 'scope', 'facilitates', 'evolution', 'potentially', 'simulations', 'encompass', 'analytical', 'insight', 'predictions', 'structural', 'considering', 'informed', 'deepen', 'focuses', 'intricately', 'security', 'enriching', 'unveils', 'superiority', 'assess', 'configurations', 'strategy', 'distinctive', 'incorporates', 'fresh', 'highlight', 'revolves', 'faced', 'specialized', 'systematic', 'edge', 'empirical', 'versatile', 'scalability', 'management', 'around', 'decisions', 'text', 'indicating', 'universe', 'influencing', 'material', 'scientific', 'resilience', 'enhancement', 'assessing', 'mitigate', 'garnered', 'effective', 'relevance', 'implementing', 'mitigating', 'consideration', 'fostering', 'seeks', 'creation', 'scenario', 'encompassing', 'imaging', 'surrounding', 'flexibility', 'unlike', 'apart', 'quality', 'identification', 'prevalent', 'tackling', 'structured', 'benefits', 'enriches', 'lens', 'operational', 'tangible', 'datasets', 'resource', 'shift', 'govern', 'medical', 'evident', 'cosmic', 'entities', 'primarily', 'strategically', 'refine', 'unveil', 'traditionally', 'expanding', 'thorough', 'leverage', 'enhancements', 'elucidate', 'cornerstone', 'pursuit', 'comprising', 'ranging', 'observation', 'extending', 'operations', 'predictive', 'holistic', 'comes', 'scrutinizing', 'considerations', 'bridging', 'unveiled', 'sets', 'drawing', 'streamlines', 'area', 'depth', 'models', 'stemming', 'arises', 'integrity', 'derivation', 'instrumental', 'mysteries', 'reducing', 'pioneering', 'conducting', 'prominent', 'face', 'interestingly', 'compromising', 'combining', 'functions', 'influenced', 'discern', 'struggle', 'objective', 'emerge', 'influences', 'discovery', 'interconnected', 'linked', 'algorithms', 'practices', 'marks', 'unveiling', 'testing', 'adapt', 'journey', 'response', 'underpinnings', 'requirements', 'scrutiny', 'uncertainties', 'managing', 'bridge', 'provides', 'efforts', 'extensive', 'rigorously', 'convergence', 'collaboration', 'encompasses', 'adoption', 'refined', 'symmetries', 'remarkably', 'ongoing', 'revolutionizing', 'against', 'experimentation', 'solely', 'exhibits', 'groundwork', 'assessments', 'alongside', 'behind', 'forth', 'necessitating', 'align', 'establishment', 'exceptional', 'mere', 'transformative', 'captivating', 'monitoring', 'akin', 'handle', 'finding', 'mathematicians', 'operates', 'focused', 'encountered', 'comparing', 'realms', 'scientists', 'imperative', 'prowess', 'operators', 'revelation', 'aids', 'crux', 'subsequent', 'advance', 'signifies', 'featuring', 'emphasis', 'encapsulates', 'streamlined', 'assessment', 'navigating', 'predicting', 'goal', 'rates', 'crafted', 'deriving', 'mechanics', 'demands', 'closely', 'adds', 'transformations', 'meaningful', 'theories', 'statistical', 'interpretability', 'emergence', 'integrates', 'practicality', 'under', 'streamlining', 'aligns', 'enigmatic', 'overarching', 'when', 'emphasizes', 'manner', 'detecting', 'demonstration', 'approximately', 'estimating', 'developing', 'surpassing', 'interventions', 'aligning', 'facilitated', 'presenting', 'driving', 'seeking', 'technological', 'hold', 'necessitates', 'functionality', 'surfaces', 'opening', 'reveals', 'aiding', 'guiding', 'particles', 'delicate', 'transparency', 'manifest', 'put', 'fall', 'dependencies', 'environmental', 'establishes', 'striking', 'diagnostic', 'doing', 'explored', 'gravitational', 'insightful', 'resources', 'testament', 'observed', 'recognizing', 'focal', 'devised', 'discourse', 'manipulation', 'era', 'multifaceted', 'heart', 'setup', 'subtle', 'bolster', 'exhibiting', 'summary', 'revolutionized', 'necessity', 'uncovering', 'invaluable', 'concrete', 'hinting', 'extension', 'pressing', 'immense', 'pinpoint', 'possess', 'surpasses', 'inquiry', 'interact', 'indicated', 'computations', 'individual', 'poised', 'building', 'evolve', 'minimizing', 'celestial', 'refinement', 'accessibility', 'attributed', 'hinges', 'delineating', 'simplifies', 'achievement', 'accessible', 'involve', 'algebras', 'predominantly', 'uncovered', 'breakthrough', 'reliance', 'safety', 'successful', 'discrepancies', 'laid', 'noted', 'alignment', 'creating', 'made', 'characterizing', 'explore', 'equations', 'underlining', 'success', 'objectives', 'illustrating', 'yielded', 'pushing', 'derived', 'heavily', 'distinguishing', 'groups', 'led', 'engineering', 'shifts', 'cater', 'perspectives', 'fusion', 'dissecting', 'revealing', 'issues', 'spanning', 'unlock', 'areas', 'discussion', 'harness', 'setups', 'details', 'elucidated', 'discoveries', 'amidst', 'rooted', 'excels', 'networks', 'scrutinized', 'enrich', 'heightened', 'team', 'proves', 'reaching', 'subsequently', 'validity', 'swiftly', 'carefully', 'renowned', 'collaborative', 'encounter', 'formulating', 'operating', 'illuminating', 'initially', 'represent', 'machine', 'clarity', 'looking', 'calculations', 'grasp', 'gleaned', 'turned', 'forefront', 'forces', 'instances', 'selecting', 'representing', 'stand', 'elucidates', 'embracing', 'pertains', 'manipulating', 'impacting', 'myriad', 'subjected', 'estimations', 'ai', 'defining', 'leveraged', 'impacts', 'strike', 'milestone', 'bolstering', 'validating', 'foundations', 'confines', 'encapsulate', 'sustainable', 'threats', 'hurdles', 'amalgamation', 'future', 'standout', 'constructs', 'seemingly', 'marked', 'unfolds', 'conjunction', 'prompting', 'developers', 'workings', 'professionals', 'targeted', 'linguistic', 'combat', 'empowers', 'strides', 'necessitate', 'discerning', 'biases', 'astronomical', 'manifolds', 'remains', 'rapid', 'offered', 'innovations', 'quantifying', 'responses', 'modern', 'trends', 'marking', 'urban', 'safeguarding', 'departure', 'adjustments', 'among', 'extracting', 'underpinning', 'wireless', 'allocation', 'pronounced', 'maximizing', 'excel', 'array', 'ascertain', 'risks', 'richness', 'rely', 'hand', 'transitions', 'inspiration', 'intriguingly', 'autonomous', 'parallels', 'varied', 'leap', 'potent', 'health', 'comprehensively', 'signals', 'illuminate', 'obstacles', 'adjusting', 'blend', 'emissions', 'simplifying', 'personalized', 'viability', 'proposal', 'alterations', 'widespread', 'harnesses', 'employs', 'serving', 'matter', 'disciplines', 'costs', 'platforms', 'throughout', 'glimpse', 'hints', 'entails', 'wealth', 'stakeholders', 'contributions', 'exceeding', 'forms', 'adhere', 'cosmos', 'proficiency', 'paradigm', 'adaptable', 'catering', 'pertinent', 'played', 'come', 'paved', 'accommodating', 'connectivity', 'feasibility', 'discussions', 'pathway', 'approaches', 'community', 'synergy', 'adapting', 'elevate', 'counterparts', 'pinpointing', 'foster', 'collective', 'disparate', 'refines', 'outlined', 'manageable', 'proven', 'functionalities', 'fluid', 'imposed', 'narrative', 'lays', 'uncovers', 'adept', 'landscapes', 'formidable', 'requiring', 'dimensions', 'maintain', 'sparked', 'proactive', 'deviations', 'interconnectedness', 'solidifying', 'differentiate', 'movements', 'credibility', 'transitioning', 'promoting', 'underpin', 'adhering', 'unlocking', 'stringent', 'engineers', 'integrated', 'improvements', 'promises', 'push', 'expands', 'concern', 'eliminating', 'how', 'laying', 'intertwined', 'collectively', 'originating', 'inaccuracies', 'situated', 'scrutinize', 'engaging', 'determination', 'infrastructure', 'prevalence', 'generalizability', 'achieved', 'progression', 'surge', 'traction', 'platform', 'protocols', 'itself', 'manipulate', 'interpreting', 'outperformed', 'overcoming', 'characteristic', 'hinder', 'deemed', 'transcends']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2eb8cde-fdea-4d67-9b2a-5cce6254976b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "human_favs = ['we', 'is', 'are', 'that', 'with', 'an', 'which', 'our', 'be', 'show', 'paper', 'using', 'based', 'propose', 'for', 'two', 'and', 'used', 'on', 'problem', 'use', 'e', 'or', 'work', 'time', 'from', 'first', 'results', 'n', 'then', 'some', 'all', 'than', 'i', 'well', 'state', 'present', 'large', 'g', 'number', 'many', 'it', 'model', 'find', 'if', 'order', 'case', 'given', 'at', 'other', 'prove', 'most', 'x', 'any', 'demonstrate', 'set', 'several', 'k', 'each', 'non', 'consider', 'via', 'here', 'finally', 'important', 'low', 'same', 'general', 'art', 'r', 'obtain', 'p', 'end', 'very', 'can', 'both', 'three', 'high', 'function', 'd', 'single', 'simple', 'over', 'small', 'network', 'a', 'there', 'recently', 't', 'm', 'no', 'so', 'will', 'class', 'available', 'introduce', 'different', 'better', 'effect', 'mathbb', 'rate', 'multi', 'investigate', 'space', 'give', 'develop', 'test', 'linear', 'c', 'h', 'discuss', 'type', 'result', '_', 'main', 'possible', 'as', 'since', 'scale', 'therefore', 'best', 'particular', 'called', 'obtained', 'f', 'new', 'shows', 'second', 'previous', 'trained', 'mathcal', 'do', 'thus', 'simulation', 'image', 'considered', 'sample', 'uses', 'because', 'applied', 'b', 'respectively', 'o', 'corresponding', 'perform', 'apply', 'estimate', 'provide', 'improve', 'solve', 'much', 'us', 'terms', 'similar', 'error', 'studied', 'shown', 'addition', 'about', 'compare', 'u', 'multiple', 'local', 'describe', 'size', 'standard', 'may', 'cost', 'found', 'respect', 'problems', 'z', 'performed', 'still', 'level', 'after', 'whose', 'source', 'v', 'outperforms', 'density', 'good', 'example', 'part', 'derive', 'point', 'presented', 'methods', 'strong', 'experiments', 'useful', 'training', 'finite', 'fast', 'literature', 'achieves', 'article', 'loss', 'reduce', 'few', 'times', 'task', 'free', 'phase', 'target', 'including', 'however', 'mass', 'input', 'images', 'does', 'cases', 'numerical', 'distribution', 'channel', 'l', 'either', 'form', 'average', 'rm', 'q', 'ii', 'probability', 'every', 'alpha', 'requires', 'independent', 'prediction', 'although', 'random', 'construct', 'they', 'mean', 'fully', 'require', 'highly', 'matrix', 'method', 'report', 'bound', 'sim', 'frequency', 'let', 'should', 'works', 'procedure', 'usually', 'train', 'compute', 'known', 'sequence', 'current', 'neural', 'design', 'learning', 'dimensional', 'investigated', 'scheme', 'proposed', 'less', 'parameters', 'difficult', 'value', 'open', 'learn', 'measured', 'higher', 'lower', 'allow', 'full', 'increasing', 'least', 'help', 'measure', 'classical', 'long', 'increase', 'hence', 'samples', '3d', 'improves', 'gradient', 'four', 'namely', 'et', 'sufficient', 'al', 'discussed', 'arbitrary', 'total', 'consists', 'able', 'cannot', 'change', 'temperature', 'limit', 'line', 'distance', 'examples', 'would', 'suggest', 'maximum', 'relative', 'delta', 'variety', 'surface', 'mathrm', 'whether', 'expected', 'fixed', 'frac', 'compared', 'cross', 'above', 'motivated', 'contains', 'omega', 'leads', 'depends', 'dependent', 'ratio', 'vector', 'major', 'according', 'mu', 'optimal', 'right', 'code', 'generate', 'infty', 'family', 'dependence', 'produce', 'positive', 'sub', 'output', 'approximation', 'y', 'search', 'described', 'consistent', 'amount', 'pre', 'makes', 'variable', 'proposes', 'policy', 'j', 'equation', 'region', 'complete', 'unknown', 'measurements', 'map', 'close', 'closed', 'strongly', 'convolutional', 'gamma', 'features', 'along', 'condition', 'hard', 'determine', 'take', 'build', 'w', 'together', 'almost', 'fact', 'generally', 'constant', 'noise', 'proved', 'estimated', 'regression', 'resolution', 'lambda', 'predict', 'illustrate', 'gives', 'modelling', 'difference', 'latter', 'dimension', 'people', 'length', 'prior', 'self', 'classification', 'global', 'special', 'having', 'instead', 'near', 'those', 'gaussian', 'spin', 'natural', 'term', 'question', 'jointly', 'behaviour', 'following', 'log', 'leq', 'measurement', 'directly', 'mainly', 'support', 'larger', 'covid', 'sigma', 'magnitude', 'solved', 'resulting', 'learned', 'popular', 'detect', 'population', 'easily', 'last', 'left', 'pair', 'showing', 'implemented', 'version', 'characterize', 'suitable', 'normal', 'boundary', 'great', 'means', 'mode', 'dataset', 'nonlinear', 'off', '2d', 'discrete', 'band', 'co', 'whole', 'define', 'upper', 'direction', 'could', 'performs', 'connected', 'information', 'coupling', 'exploit', 'generated', 'reported', 'automatic', 'signal', 'recent', 'besides', 'supervised', 'typical', 'interaction', 'optical', 'relation', 'identify', 'zero', 'ones', 'etc', 'approximate', 'score', 'estimates', 'plane', 'defined', 'collected', 'required', 'location', 'computed', 'deep', 'equivalent', 'distributed', 'geq', 'latent', 'enough', 'asymptotic', 'deal', 'experimentally', 'formulate', 'currently', 'showed', 'baseline', 'purpose', 'inference', 'm_', 'ray', 'regime', 'beta', 'increases', 'explicitly', 'next', 'sense', 'needed', 'exact', 'convex', 'sampling', 'velocity', 'original', 'joint', 'bounded', 'verify', 'done', 'explain', 'https', 'ml', 'run', 'description', 'patients', 'determined', 'energy', 'combined', 'little', 'estimator', 'depend', 'evaluated', 'observe', 're', 'basic', 'pi', 'human', 'emph', 'emission', 'kernel', 'big', 'automatically', 'far', 'examine', 'depending', 'pm', 'invariant', 'assume', 'online', 'without', 'continuous', 'states', 'active', 'ground', 'cite', 'iii', 'produces', 'widely', 'conclude', 'textit', 'reduces', 'frame', 'extremely', 'path', 'implement', 'though', 'massive', 'fit', 'tested', 'node', 'block', 'faster', 'memory', 'product', 'graph', 'relevant', 'review', 'whereas', 'make', 'performing', 'minimum', 'generic', 'yields', 'argue', 'negative', 'motion', 'generalized', 'vehicle', 'parameter', 'labels', 'taking', 'indicate', 'proper', 'background', 'basis', 'embedding', 'variation', 'sum', 'likely', 'cause', 'com', 'driven', 'weak', 'explicit', 'rank', 'agent', 'related', 'sparse', 'numerically', 'before', 'assuming', '_2', 'naturally', 'conditional', 'exists', 'gas', 'easy', 'reference', 'loop', 'radio', 'get', 'assumption', 'cell', 'semi', 'data', 'delay', 'cluster', 'detected', 'subset', 'contrast', 'weighted', 'contain', 'calculate', 'call', 'attack', 'expensive', 'confirm', 'device', 'appear', 'binary', 'object', 'previously', 'per', 'label', 'classes', 'inside', 'mixed', 'adversarial', 'bias', 'certain', 'avoid', 'built', 'being', 'learns', 'caused', 'degree', 'generative', 'likelihood', 'nodes', 'evaluate', 'partial', 'benchmark', 'direct', 'necessary', 'side', 'selected', 'bounds', 'algorithm', 'completely', 'limited', 'correlation', 'them', 'temporal', 'publicly', 'answer', 'video', 'transfer', 'too', 'fraction', 'stable', 'years', 'account', 'controller', 'consisting', 'describes', 'flow', 'simulated', 'posterior', 'correct', 'calculated', 'combine', 'parts', 'third', 'inspired', 'wise', 'ge', 'action', 'matching', 'smaller', 'parametric', 'sufficiently', 'volume', 'module', 'survey', 'bulk', 'heterogeneous', 'experiment', 'inverse', 'cnn', 'possibly', 'synthetic', 'phi', 'already', 'factor', 'modeled', 'unit', 'mixture', 'produced', 'symmetric', 'top', 'interesting', 'exist', 'variance', 'weight', 'relatively', 'view', 'past', 'exploiting', 'odot', 'uncertainty', 'maps', 'rather', 'mathbf', 'exactly', 'index', 'agreement', 'flux', 'law', 'conduct', 'filter', 'epsilon', 'satisfy', 'empirically', 'assumed', 'base', 'constructed', 'sqrt', 'encoder', 'angle', 'stationary', 'quite', 'carlo', 'charge', 'predicted', 'theoretically', 'follow', 'layer', 'monte', 'select', 'constraint', 'cloud', 'weights', 'electron', 'mostly', 'compact', 'appropriate', 'even', 'computation', 'box', 'le', 'database', 'generates', 'five', 'feature', 'physical', 'period', 'magnetic', 'classifier', 'spectra', 'taken', 'star', 'inter', 'final', 'reduced', 'load', 'relations', 'performances', 'classify', 'transition', 'series', 'trivial', 'due', 'origin', 'bar', 'infinite', 'variables', 'containing', 'tree', 'coefficient', 'smooth', 'stochastic', 'group', 'yet', 'disk', 'always', 'might', 'convolution', 'schemes', 'correlated', 'asymptotically', 'recover', 'values', 'residual', 'mathfrak', 'valid', 'quadratic', 'half', 'beam', 'verified', 'induced', 'include', 'complicated', 'semantic', 'profile', 'received', 'reveal', 'wide', 'analyse', 'excellent', 'largest', 'unsupervised', 'idea', 'receiver', 'cm', 'affected', 'comparable', 'provided', 'short', 'published', 'consequence', 'additional', 'computationally', 'applicable', 'implies', 'illustrated', 'orthogonal', 'includes', 'sharp', 'formulated', 'hardware', 'theta', 'chain', 'integer', 'kind', 'toward', 'setting', 'amplitude', 'user', 'statistics', 'approx', 'nu', 'locally', 'cycle', 'service', 'body', 'lines', 'event', 'suffer', 'parallel', 'satisfying', 'update', 'multivariate', 'detector', 'extracted', 'exploits', 'spatial', 'functional', 'situation', 'guarantee', 'layers', 'observations', 'users', 'utilize', 'see', 'reason', 'quasi', 'employ', 'pixel', 'simultaneously', 'common', 'noisy', 'tau', 'flexible', 'github', 'dl', 'static', 'de', 'greatly', 'difficulty', 'polynomial', 'sensitive', 'dense', 'possibility', 'advances', 'diffusion', 'orders', 'net', 'mobile', 'satisfies', 'must', 'projection', 'wave', 'practice', 'uniform', 'pressure', 'slow', 'segmentation', 'momentum', 'baselines', 'regular', 'markov', 'composed', 'subjects', 'investigates', 'modes', 'double', 'huge', 'analyzed', 'position', 'turn', 'usual', 'generalizes', 'intermediate', 'adopted', 'admits', 'dynamical', 'word', 'analytically', 'poor', 'compatible', 'similarity', 'definition', 'outperform', 'nearly', 'transmit', 'em', 'decoder', 'followed', 'day', 'mm', 'spatially', 'camera', 'aware', 'acoustic', 'vertex', 'fail', 'created', 'letter', 'appears', 'proof', 'photon', 'segment', 'program', 'pairs', 'force', 'variational', 'fashion', 'affect', 'competitive', 'applies', 'bit', 'substantially', 'scalar', 'decomposition', 'benefit', 'others', 'covariance', 'scales', 'varepsilon', 'adopt', 'largely', 'shape', 'homogeneous', 'match', 'generalize', 'control', 'rule', 'priori', 'dnn', 'ldots', 'turns', 'intensity', 'modified', 'achieve', 'ct', 'curve', 'entropy', 'representative', 'now', 'extra', 'realize', 'explained', 'grained', 'detection', 'disc', 'candidate', 'necessarily', 'highest', 'social', 'radius', 'extend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8ddb4f47-1c99-46cd-a0fc-45e2e23eb7a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stopwords = ['i', 'within', 'me', 'my', 'myself', 'we', 'our', 'ours', \n",
    "'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', \n",
    "'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', \n",
    "'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    " 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are',\n",
    " 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing',\n",
    " 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', \n",
    "'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', \n",
    "'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', \n",
    "'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', \n",
    "'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \n",
    "'s', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y',\n",
    " 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", \n",
    "'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn',\n",
    " \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", \n",
    "'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\",  'moreover',\n",
    "'aims', 'across', 'utilizing', 'furthermore', 'way', 'e', 'g', 'n', 'two', 'amidst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d948c203-f591-49cf-8936-8edc0bb7e809",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['delve', 'underscores', 'delving', 'delves', 'underscored', 'underscoring', 'intricacies', 'groundbreaking', 'scrutinizing', 'meticulous', 'realm', 'meticulously', 'showcases', 'prowess', 'signifies', 'tapestry', 'intricately', 'bolster', 'intricate', 'showcasing', 'dissecting', 'mysteries', 'bolstering', 'unraveling', 'underscore', 'nuanced', 'revolutionize', 'transcends', 'elegance', 'glean', 'revolves', 'nuances', 'amalgamating', 'endeavors', 'underlining', 'embark', 'revolutionizing', 'scrutinized', 'deepen', 'renowned', 'illuminating', 'culminating', 'unearthed', 'solidifies', 'posits', 'culmination', 'pivotal', 'tangible', 'unveils', 'unravels', 'endeavor', 'commendable', 'profound', 'embarked', 'upholding', 'shines', 'fostering', 'adeptly', 'showcased', 'shedding', 'inquiries', 'fascinating', 'feat', 'unravel', 'interconnectedness', 'heightened', 'uphold', 'heralding', 'swiftly', 'elucidating', 'groundwork', 'gleaned', 'bolsters', 'streamlines', 'comprehending', 'elucidation', 'hinting', 'juxtaposing', 'advancing', 'illuminates', 'quest', 'hinted', 'avenues', 'falter', 'underpinnings', 'streamlining', 'safeguarding', 'ventures', 'offering', 'strives', 'intriguing', 'methodical', 'interrelations', 'mathematicians', 'innovative', 'essence', 'crux', 'advancement', 'grappling', 'paving']\n"
     ]
    }
   ],
   "source": [
    "ai_favs_clean = [x for x in ai_best_of_best[:101] if x not in stopwords]\n",
    "print(ai_favs_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4e0a6e0e-b707-4965-97d7-23ea1eae2b46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['understanding', 'researchers', 'approach', 'intricate', 'crucial', 'realm', 'insights', 'significant', 'research', 'various', 'study', 'analysis', 'systems', 'behavior', 'potential', 'light', 'framework', 'process', 'scenarios', 'comprehensive']\n",
      "['show', 'paper', 'using', 'based', 'propose', 'used', 'problem', 'use', 'work', 'time', 'first', 'results', 'well', 'state', 'present', 'large', 'number', 'many', 'model', 'find']\n"
     ]
    }
   ],
   "source": [
    "ai_favs_clean = ai_favs_clean[:20]\n",
    "human_favs_clean = human_favs_clean[:20]\n",
    "\n",
    "print(ai_favs_clean)\n",
    "print(human_favs_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d4886e1-23cb-4a66-91a0-2bd10b4fcf7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "control = ['first', 'km', 'equation', 'nearly', 'energy', 'system', 'evidence', 'process', 'data', 'time', 'type', 'tests', 'sup', 'product', 'upper', 'dark', 'balloon', 'absorption', 'threaded', 'present', 'geothermal', 'rip', 'assumed', 'describing', 'satellite', 'clusters', 'nearest', 'ocean', 'thin', 'almost', 'eastern', 'arctic', 'slope', 'dynamics', 'associated', 'peak', 'space', 'plasma', 'ricky', 'consequences', 'concepts', 'density', 'compose', 'orbits', 'introduce', 'best', 'zones', 'sub', 'systems', 'changes', 'jem', 'motion', 'hoc', 'green', 'hand', 'agb', 'drawn', 'cloud', 'ego', 'cassini', 'observed', 'stars', 'fields', 'analysis', 'lengths', 'injection', 'processing', 'source', 'surface', 'various', 'quark', 'oh', 'fluctuations', 'populations', 'mpc', 'dwarf', 'overview', 'scale', 'size', 'axes', 'even', 'ecosystem', 'reside', 'propagation', 'model', 'main', 'still', 'driven', 'lights', 'agreement', 'life', 'propose', 'quartic', 'observations', 'hi', 'nwa', 'reference', 'nature', 'use', 'spectroscopy', 'richness', 'dominated']\n",
    "control.remove('best')\n",
    "control.remove('almost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e10b26e-f3d2-44bb-ab77-8cd95a5b1cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are 1% done\n",
      "We are 2% done\n",
      "We are 3% done\n",
      "We are 4% done\n",
      "We are 5% done\n",
      "We are 6% done\n",
      "We are 7% done\n",
      "We are 8% done\n",
      "We are 9% done\n",
      "We are 10% done\n",
      "We are 11% done\n",
      "We are 12% done\n",
      "We are 13% done\n",
      "We are 14% done\n",
      "We are 15% done\n",
      "We are 16% done\n",
      "We are 17% done\n",
      "We are 18% done\n",
      "We are 19% done\n",
      "We are 20% done\n",
      "We are 21% done\n",
      "We are 22% done\n",
      "We are 23% done\n",
      "We are 24% done\n",
      "We are 25% done\n",
      "We are 26% done\n",
      "We are 27% done\n",
      "We are 28% done\n",
      "We are 29% done\n",
      "We are 30% done\n",
      "We are 31% done\n",
      "We are 32% done\n",
      "We are 33% done\n",
      "We are 34% done\n",
      "We are 35% done\n",
      "We are 36% done\n",
      "We are 37% done\n",
      "We are 38% done\n",
      "We are 39% done\n",
      "We are 40% done\n",
      "We are 41% done\n",
      "We are 42% done\n",
      "We are 43% done\n",
      "We are 44% done\n",
      "We are 45% done\n",
      "We are 46% done\n",
      "We are 47% done\n",
      "We are 48% done\n",
      "We are 49% done\n",
      "We are 50% done\n",
      "We are 51% done\n",
      "We are 52% done\n",
      "We are 53% done\n",
      "We are 54% done\n",
      "We are 55% done\n",
      "We are 56% done\n",
      "We are 57% done\n",
      "We are 58% done\n",
      "We are 59% done\n",
      "We are 60% done\n",
      "We are 61% done\n",
      "We are 62% done\n",
      "We are 63% done\n",
      "We are 64% done\n",
      "We are 65% done\n",
      "We are 66% done\n",
      "We are 67% done\n",
      "We are 68% done\n",
      "We are 69% done\n",
      "We are 70% done\n",
      "We are 71% done\n",
      "We are 72% done\n",
      "We are 73% done\n",
      "We are 74% done\n",
      "We are 75% done\n",
      "We are 76% done\n",
      "We are 77% done\n",
      "We are 78% done\n",
      "We are 79% done\n",
      "We are 80% done\n",
      "We are 81% done\n",
      "We are 82% done\n",
      "We are 83% done\n",
      "We are 84% done\n",
      "We are 85% done\n",
      "We are 86% done\n",
      "We are 87% done\n",
      "We are 88% done\n",
      "We are 89% done\n",
      "We are 90% done\n",
      "We are 91% done\n",
      "We are 92% done\n",
      "We are 93% done\n",
      "We are 94% done\n",
      "We are 95% done\n",
      "We are 96% done\n",
      "We are 97% done\n",
      "We are 98% done\n",
      "We are 99% done\n",
      "We are 100% done\n"
     ]
    }
   ],
   "source": [
    "count_papers_control_red = {}\n",
    "for word in control:\n",
    "    count_papers_control_red[word] = {}\n",
    "    count_papers_word = astro_search(word)\n",
    "    count_papers_word_freq = {}\n",
    "    for year in range(2000,2025):\n",
    "        count_papers_word_freq[str(year)] = count_papers_word[str(year)]/documents_per_year[str(year)]\n",
    "    count_papers_control_red[word]['absolute'] = count_papers_word\n",
    "    count_papers_control_red[word]['frequency'] = count_papers_word_freq\n",
    "    print(f'We are {control.index(word)+1}% done')\n",
    "\n",
    "with open('count_papers_control_red.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(count_papers_control_red, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57400252-6210-4897-9d43-8ff7911bab3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('count_papers_control_notred.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(count_papers_control_red, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "24b2a53f-9ee9-426b-a831-77464b44d19d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "with open('/media/home/team_workspaces/ESA-science-NLP/Simone_Astarita/delve_project/ads_nasa_api/count_papers_control.json') as f:\n",
    "    count_papers_control = json.load(f)\n",
    "\n",
    "count_papers_control.pop('almost')\n",
    "count_papers_control.pop('best')\n",
    "\n",
    "subs = ['richness', 'dominated']\n",
    "\n",
    "for word in subs:\n",
    "    count_papers_control[word] = {}\n",
    "    count_papers_word = astro_search(word)\n",
    "    count_papers_word_freq = {}\n",
    "    for year in range(2000,2025):\n",
    "        count_papers_word_freq[str(year)] = count_papers_word[str(year)]/documents_per_year[str(year)]\n",
    "    count_papers_control[word]['absolute'] = count_papers_word\n",
    "    if count_papers_control[word]['absolute']['2023'] == 0:\n",
    "        print(f'help the word {word} is not good')\n",
    "    count_papers_control[word]['frequency'] = count_papers_word_freq\n",
    "\n",
    "print('done')\n",
    "\n",
    "with open('count_papers_control.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(count_papers_control, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1562639f-1cf5-4350-8657-8bc55cfebdb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('count_papers_ai_favs_articles_best_of_best.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(count_papers_ai_favs, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb0e60a0-3c13-4f4c-901a-754638037cf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_of_words = ['understanding', 'researchers', 'approach', 'intricate', 'crucial', 'realm', 'insights', 'significant', 'research', 'various', 'study', 'analysis', 'systems', 'behavior', 'potential', 'light', 'framework', 'process', 'scenarios', 'comprehensive', 'leveraging', 'enhancing', 'enhance', 'offering', 'key', 'innovative', 'complex', 'efficiency', 'particularly', 'valuable', 'role', 'challenges', 'techniques', 'exploration', 'novel', 'involves', 'effectively', 'efficacy', 'lies', 'properties', 'dynamics', 'context', 'practical', 'specific', 'diverse', 'mathematical', 'interplay', 'deeper', 'address', 'aspect', 'performance', 'traditional', 'effectiveness', 'one', 'applications', 'structures', 'overall', 'accuracy', 'play', 'ability', 'showcasing', 'theoretical', 'fundamental', 'capabilities', 'underlying', 'intriguing', 'underscores', 'pivotal', 'offers', 'ensuring', 'field', 'system', 'unique', 'implications', 'promising', 'investigation', 'conducted', 'characteristics', 'shedding', 'exploring', 'findings', 'delve', 'challenge', 'essential', 'notable', 'delves', 'world', 'advancements', 'reliability', 'utilization', 'enabling', 'processes', 'methodology', 'nature', 'critical', 'providing', 'robustness', 'tailored', 'making', 'concept']\n",
    "\n",
    "for word in list_of_words:\n",
    "    if count_papers_ai_favs[word]['absolute']['2024'] == 0:\n",
    "        list_of_words.remove(word)\n",
    "\n",
    "frequencies_2024 = []\n",
    "frequencies_2023 = []\n",
    "frequencies_2022 = []\n",
    "frequencies_2021 = []\n",
    "frequencies_2020 = []\n",
    "frequencies_2019 = []\n",
    "frequencies_2018 = []\n",
    "frequencies_2017 = []\n",
    "frequencies_2016 = []\n",
    "frequencies_2015 = []\n",
    "frequencies_2014 = []\n",
    "frequencies_2013 = []\n",
    "frequencies_2012 = []\n",
    "frequencies_2011 = []\n",
    "frequencies_2010 = []\n",
    "frequencies_2009 = []\n",
    "frequencies_2008 = []\n",
    "frequencies_2007 = []\n",
    "frequencies_2006 = []\n",
    "frequencies_2005 = []\n",
    "frequencies_2004 = []\n",
    "frequencies_2003 = []\n",
    "frequencies_2002 = []\n",
    "frequencies_2001 = []\n",
    "frequencies_2000 = []\n",
    "\n",
    "for word in list_of_words:\n",
    "    frequencies_2024.append(count_papers_ai_favs[word]['frequency']['2024'])\n",
    "    frequencies_2023.append(count_papers_ai_favs[word]['frequency']['2023'])\n",
    "    frequencies_2022.append(count_papers_ai_favs[word]['frequency']['2022'])\n",
    "    frequencies_2021.append(count_papers_ai_favs[word]['frequency']['2021'])\n",
    "    frequencies_2020.append(count_papers_ai_favs[word]['frequency']['2020'])\n",
    "    frequencies_2019.append(count_papers_ai_favs[word]['frequency']['2019'])\n",
    "    frequencies_2018.append(count_papers_ai_favs[word]['frequency']['2018'])\n",
    "    frequencies_2017.append(count_papers_ai_favs[word]['frequency']['2017'])\n",
    "    frequencies_2016.append(count_papers_ai_favs[word]['frequency']['2016'])\n",
    "    frequencies_2015.append(count_papers_ai_favs[word]['frequency']['2015'])\n",
    "    frequencies_2014.append(count_papers_ai_favs[word]['frequency']['2014'])\n",
    "    frequencies_2013.append(count_papers_ai_favs[word]['frequency']['2013'])\n",
    "    frequencies_2012.append(count_papers_ai_favs[word]['frequency']['2012'])\n",
    "    frequencies_2011.append(count_papers_ai_favs[word]['frequency']['2011'])\n",
    "    frequencies_2010.append(count_papers_ai_favs[word]['frequency']['2010'])\n",
    "    frequencies_2009.append(count_papers_ai_favs[word]['frequency']['2009'])\n",
    "    frequencies_2008.append(count_papers_ai_favs[word]['frequency']['2008'])\n",
    "    frequencies_2007.append(count_papers_ai_favs[word]['frequency']['2007'])\n",
    "    frequencies_2006.append(count_papers_ai_favs[word]['frequency']['2006'])\n",
    "    frequencies_2005.append(count_papers_ai_favs[word]['frequency']['2005'])\n",
    "    frequencies_2004.append(count_papers_ai_favs[word]['frequency']['2004'])\n",
    "    frequencies_2003.append(count_papers_ai_favs[word]['frequency']['2003'])\n",
    "    frequencies_2002.append(count_papers_ai_favs[word]['frequency']['2002'])\n",
    "    frequencies_2001.append(count_papers_ai_favs[word]['frequency']['2001'])\n",
    "    frequencies_2000.append(count_papers_ai_favs[word]['frequency']['2000'])\n",
    "\n",
    "list_of_fr = [frequencies_2000, frequencies_2001, frequencies_2002, frequencies_2003, frequencies_2004, frequencies_2005, frequencies_2006, frequencies_2007, frequencies_2008,\n",
    "              frequencies_2009, frequencies_2010, frequencies_2011, frequencies_2012, frequencies_2013, frequencies_2014, frequencies_2015, frequencies_2016, frequencies_2017,\n",
    "              frequencies_2018, frequencies_2019, frequencies_2020, frequencies_2021, frequencies_2022, frequencies_2023, frequencies_2024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "930431fa-f2e6-41ff-808c-27530d6f8177",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ks_2samp\n\u001b[1;32m      2\u001b[0m dictionary_pvalues \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      3\u001b[0m number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1999\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "dictionary_pvalues = {}\n",
    "number = 1999\n",
    "for fr1 in list_of_fr:\n",
    "    number += 1\n",
    "    dictionary_pvalues[str(number)] = {}\n",
    "    for fr2 in range(2000,2025):\n",
    "        dictionary_pvalues[str(number)][str(fr2)] = ks_2samp(data1=fr1, data2=list_of_fr[fr2-2000])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf80fe44-752e-4b95-a6ff-f5e9036efbf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
